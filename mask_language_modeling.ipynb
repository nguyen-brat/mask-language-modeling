{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nguyen-brat/mask-language-modeling/blob/main/mask_language_modeling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KkYK7McTANjD"
      },
      "source": [
        "#IMPORT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gQ7pcZ1t07pz"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras\n",
        "import os\n",
        "import pandas as pd\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "8jlnMhqa_mk6"
      },
      "outputs": [],
      "source": [
        "mask_percent = 0.15 # percent data replace with mask\n",
        "train_size = 0.8\n",
        "valid_size = 0.1\n",
        "test_size = 0.1\n",
        "max_len = 256 # max len of input feed to neuron network\n",
        "max_dim = 128 # world embedding dimention\n",
        "batch_size = 32\n",
        "num_epochs = 4\n",
        "n_blocks = 2 # n transformer block\n",
        "lr = 0.01 # learning rate\n",
        "n_heads = 8 # n_head in transformer block\n",
        "drop_rate = 0.1 # drop rate in transformer block\n",
        "freq_word = 30 # remove all world below freq_word\n",
        "d_dim = 256 # dimention in FFN layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-k4HkeZpNwbS"
      },
      "source": [
        "# PREPROCESSING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ILaCQvDox0us",
        "outputId": "4071c766-8d29-467d-db9f-a9cf1a87f872"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "KjcNeNCv1hi6"
      },
      "outputs": [],
      "source": [
        "#!unzip /content/drive/MyDrive/book_text.zip -d /content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "kRpzs-k21h5J"
      },
      "outputs": [],
      "source": [
        "list_data = []\n",
        "with open('/content/booksummaries.txt', 'r') as f:\n",
        "  data = f.readlines()\n",
        "  for line in data:\n",
        "    list_data.append(line.split('\\t')[6])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "id": "wpDO-DuEW2rN",
        "outputId": "1f9bb579-e1ca-4e08-b716-03d49c4b46f8"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' Old Major, the old boar on the Manor Farm, calls the animals on the farm for a meeting, where he compares the humans to parasites and teaches the animals a revolutionary song, \\'Beasts of England\\'. When Major dies, two young pigs, Snowball and Napoleon, assume command and turn his dream into a philosophy. The animals revolt and drive the drunken and irresponsible Mr Jones from the farm, renaming it \"Animal Farm\". They adopt Seven Commandments of Animal-ism, the most important of which is, \"All animals are equal\". Snowball attempts to teach the animals reading and writing; food is plentiful, and the farm runs smoothly. The pigs elevate themselves to positions of leadership and set aside special food items, ostensibly for their personal health. Napoleon takes the pups from the farm dogs and trains them privately. Napoleon and Snowball struggle for leadership. When Snowball announces his plans to build a windmill, Napoleon has his dogs chase Snowball away and declares himself leader. Napoleon enacts changes to the governance structure of the farm, replacing meetings with a committee of pigs, who will run the farm. Using a young pig named Squealer as a \"mouthpiece\", Napoleon claims credit for the windmill idea. The animals work harder with the promise of easier lives with the windmill. After a violent storm, the animals find the windmill annihilated. Napoleon and Squealer convince the animals that Snowball destroyed it, although the scorn of the neighbouring farmers suggests that its walls were too thin. Once Snowball becomes a scapegoat, Napoleon begins purging the farm with his dogs, killing animals he accuses of consorting with his old rival. He and the pigs abuse their power, imposing more control while reserving privileges for themselves and rewriting history, villainising Snowball and glorifying Napoleon. Squealer justifies every statement Napoleon makes, even the pigs\\' alteration of the Seven Commandments of Animalism to benefit themselves. \\'Beasts of England\\' is replaced by an anthem glorifying Napoleon, who appears to be adopting the lifestyle of a man. The animals remain convinced that they are better off than they were when under Mr Jones. Squealer abuses the animals\\' poor memories and invents numbers to show their improvement. Mr Frederick, one of the neighbouring farmers, attacks the farm, using blasting powder to blow up the restored windmill. Though the animals win the battle, they do so at great cost, as many, including Boxer the workhorse, are wounded. Despite his injuries, Boxer continues working harder and harder, until he collapses while working on the windmill. Napoleon sends for a van to take Boxer to the veterinary surgeon\\'s, explaining that better care can be given there. Benjamin, the cynical donkey, who \"could read as well as any pig\", notices that the van belongs to a knacker, and attempts to mount a rescue; but the animals\\' attempts are futile. Squealer reports that the van was purchased by the hospital and the writing from the previous owner had not been repainted. He recounts a tale of Boxer\\'s death in the hands of the best medical care. Years pass, and the pigs learn to walk upright, carry whips and wear clothes. The Seven Commandments are reduced to a single phrase: \"All animals are equal, but some animals are more equal than others\". Napoleon holds a dinner party for the pigs and the humans of the area, who congratulate Napoleon on having the hardest-working but least fed animals in the country. Napoleon announces an alliance with the humans, against the labouring classes of both \"worlds\". He abolishes practices and traditions related to the Revolution, and changes the name of the farm to \"The Manor Farm\". The animals, overhearing the conversation, notice that the faces of the pigs have begun changing. During a poker match, an argument breaks out between Napoleon and Mr Pilkington, and the animals realise that the faces of the pigs look like the faces of humans, and no one can tell the difference between them. The pigs Snowball, Napoleon, and Squealer adapt Old Major\\'s ideas into an actual philosophy, which they formally name Animalism. Soon after, Napoleon and Squealer indulge in the vices of humans (drinking alcohol, sleeping in beds, trading). Squealer is employed to alter the Seven Commandments to account for this humanisation, an allusion to the Soviet government\\'s revising of history in order to exercise control of the people\\'s beliefs about themselves and their society. The original commandments are: # Whatever goes upon two legs is an enemy. # Whatever goes upon four legs, or has wings, is a friend. # No animal shall wear clothes. # No animal shall sleep in a bed. # No animal shall drink alcohol. # No animal shall kill any other animal. # All animals are equal. Later, Napoleon and his pigs secretly revise some commandments to clear them of accusations of law-breaking (such as \"No animal shall drink alcohol\" having \"to excess\" appended to it and \"No animal shall sleep in a bed\" with \"with sheets\" added to it). The changed commandments are as follows, with the changes bolded: * 4 No animal shall sleep in a bed with sheets. * 5 No animal shall drink alcohol to excess. * 6 No animal shall kill any other animal without cause. Eventually these are replaced with the maxims, \"All animals are equal, but some animals are more equal than others\", and \"Four legs good, two legs better!\" as the pigs become more human. This is an ironic twist to the original purpose of the Seven Commandments, which were supposed to keep order within Animal Farm by uniting the animals together against the humans, and prevent animals from following the humans\\' evil habits. Through the revision of the commandments, Orwell demonstrates how simply political dogma can be turned into malleable propaganda.\\n'"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "list_data[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "keJw5sf514cR"
      },
      "outputs": [],
      "source": [
        "for i, line in enumerate(list_data):\n",
        "  list_data[i] = list_data[i][:-2].lower()\n",
        "  list_data[i] = re.sub('[^a-zA-Z0-9\\s]', '' ,list_data[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "id": "kJd4HNvu32Fg",
        "outputId": "c3ba6901-378b-4cd9-86cc-a2c3aad60477"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' old major the old boar on the manor farm calls the animals on the farm for a meeting where he compares the humans to parasites and teaches the animals a revolutionary song beasts of england when major dies two young pigs snowball and napoleon assume command and turn his dream into a philosophy the animals revolt and drive the drunken and irresponsible mr jones from the farm renaming it animal farm they adopt seven commandments of animalism the most important of which is all animals are equal snowball attempts to teach the animals reading and writing food is plentiful and the farm runs smoothly the pigs elevate themselves to positions of leadership and set aside special food items ostensibly for their personal health napoleon takes the pups from the farm dogs and trains them privately napoleon and snowball struggle for leadership when snowball announces his plans to build a windmill napoleon has his dogs chase snowball away and declares himself leader napoleon enacts changes to the governance structure of the farm replacing meetings with a committee of pigs who will run the farm using a young pig named squealer as a mouthpiece napoleon claims credit for the windmill idea the animals work harder with the promise of easier lives with the windmill after a violent storm the animals find the windmill annihilated napoleon and squealer convince the animals that snowball destroyed it although the scorn of the neighbouring farmers suggests that its walls were too thin once snowball becomes a scapegoat napoleon begins purging the farm with his dogs killing animals he accuses of consorting with his old rival he and the pigs abuse their power imposing more control while reserving privileges for themselves and rewriting history villainising snowball and glorifying napoleon squealer justifies every statement napoleon makes even the pigs alteration of the seven commandments of animalism to benefit themselves beasts of england is replaced by an anthem glorifying napoleon who appears to be adopting the lifestyle of a man the animals remain convinced that they are better off than they were when under mr jones squealer abuses the animals poor memories and invents numbers to show their improvement mr frederick one of the neighbouring farmers attacks the farm using blasting powder to blow up the restored windmill though the animals win the battle they do so at great cost as many including boxer the workhorse are wounded despite his injuries boxer continues working harder and harder until he collapses while working on the windmill napoleon sends for a van to take boxer to the veterinary surgeons explaining that better care can be given there benjamin the cynical donkey who could read as well as any pig notices that the van belongs to a knacker and attempts to mount a rescue but the animals attempts are futile squealer reports that the van was purchased by the hospital and the writing from the previous owner had not been repainted he recounts a tale of boxers death in the hands of the best medical care years pass and the pigs learn to walk upright carry whips and wear clothes the seven commandments are reduced to a single phrase all animals are equal but some animals are more equal than others napoleon holds a dinner party for the pigs and the humans of the area who congratulate napoleon on having the hardestworking but least fed animals in the country napoleon announces an alliance with the humans against the labouring classes of both worlds he abolishes practices and traditions related to the revolution and changes the name of the farm to the manor farm the animals overhearing the conversation notice that the faces of the pigs have begun changing during a poker match an argument breaks out between napoleon and mr pilkington and the animals realise that the faces of the pigs look like the faces of humans and no one can tell the difference between them the pigs snowball napoleon and squealer adapt old majors ideas into an actual philosophy which they formally name animalism soon after napoleon and squealer indulge in the vices of humans drinking alcohol sleeping in beds trading squealer is employed to alter the seven commandments to account for this humanisation an allusion to the soviet governments revising of history in order to exercise control of the peoples beliefs about themselves and their society the original commandments are  whatever goes upon two legs is an enemy  whatever goes upon four legs or has wings is a friend  no animal shall wear clothes  no animal shall sleep in a bed  no animal shall drink alcohol  no animal shall kill any other animal  all animals are equal later napoleon and his pigs secretly revise some commandments to clear them of accusations of lawbreaking such as no animal shall drink alcohol having to excess appended to it and no animal shall sleep in a bed with with sheets added to it the changed commandments are as follows with the changes bolded  4 no animal shall sleep in a bed with sheets  5 no animal shall drink alcohol to excess  6 no animal shall kill any other animal without cause eventually these are replaced with the maxims all animals are equal but some animals are more equal than others and four legs good two legs better as the pigs become more human this is an ironic twist to the original purpose of the seven commandments which were supposed to keep order within animal farm by uniting the animals together against the humans and prevent animals from following the humans evil habits through the revision of the commandments orwell demonstrates how simply political dogma can be turned into malleable propaganda'"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "list_data[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "YODpnLoxCYos"
      },
      "outputs": [],
      "source": [
        "corpus = set()\n",
        "for data in list_data:\n",
        "  corpus.update(data.split())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "IPJ_s8rO_k1U"
      },
      "outputs": [],
      "source": [
        "corpus_freq = {word : 0 for word in corpus}\n",
        "for data in list_data:\n",
        "  for word in data.split():\n",
        "    corpus_freq[word] += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "V2X2UCPfEb1B"
      },
      "outputs": [],
      "source": [
        "short_corpus = [word for word, freq in corpus_freq.items() if freq > freq_word]\n",
        "eliminate_corpus = [word for word, freq in corpus_freq.items() if freq <= freq_word]\n",
        "short_corpus = ['[PAD]', '[MASK]'] + short_corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Tfc7Z2wn17QP"
      },
      "outputs": [],
      "source": [
        "words = tf.constant(short_corpus)\n",
        "word_ids = tf.range(len(short_corpus), dtype=tf.int64)\n",
        "vocab_init = tf.lookup.KeyValueTensorInitializer(words, word_ids)\n",
        "num_oov_buckets = 1000\n",
        "table = tf.lookup.StaticVocabularyTable(vocab_init, num_oov_buckets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "k-e66Hziq_vQ"
      },
      "outputs": [],
      "source": [
        "corpus_len = len(short_corpus) + num_oov_buckets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "SYBEPumDKB70"
      },
      "outputs": [],
      "source": [
        "train_data, valid_data = train_test_split(list_data, train_size = train_size, test_size = test_size+valid_size, random_state = 42)\n",
        "valid_data, test_data =  train_test_split(valid_data, train_size = valid_size/(valid_size+test_size), test_size=test_size/(valid_size+test_size), random_state = 42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "A4nqE2dWmDHz",
        "outputId": "f94deb1c-0ea1-4017-9248-ac6229b6c8fe"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "list_len = np.array([len(data.split()) for data in list_data])\n",
        "plt.hist(np.array(list_len), bins = 30)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "cG4HtZn5AAAp"
      },
      "outputs": [],
      "source": [
        "def MaskingData(texts, mask_rate = mask_percent):\n",
        "  mask_texts = []\n",
        "  one_hot_masks = []\n",
        "  non_masks = []\n",
        "  for text in texts:\n",
        "    text = text.split()\n",
        "    random_mask_id = np.random.randint(0, len(text), size = int(len(text)*mask_rate))\n",
        "    one_hot_mask = np.zeros(shape = len(text))\n",
        "    one_hot_mask[random_mask_id] = 1\n",
        "    one_hot_masks.append(one_hot_mask)\n",
        "    text = np.array(text)\n",
        "    raw_text = np.copy(text)\n",
        "    text[random_mask_id] = '[MASK]'\n",
        "    mask_texts.append(text)\n",
        "    non_masks.append(raw_text)\n",
        "  return non_masks, mask_texts, one_hot_masks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "uAffebtp3MeG"
      },
      "outputs": [],
      "source": [
        "mask_id = short_corpus.index('[MASK]')\n",
        "def encode_sentence(text):\n",
        "  return list(table.lookup(tf.constant(text.split())).numpy())\n",
        "def encode_sentences(texts):\n",
        "  output = []\n",
        "  for text in texts:\n",
        "    output.append(table.lookup(tf.constant(text)).numpy())\n",
        "  return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "7arR9cFfwGTg"
      },
      "outputs": [],
      "source": [
        "def PaddingData(encode_non_mask_texts, encode_mask_texts, mask_ids, max_len = max_len):\n",
        "  padding_ids = []\n",
        "  pad_masks = []\n",
        "  pad_mask_texts = []\n",
        "  pad_non_mask_texts = []\n",
        "  for mask_text, non_mask_text, mask_id in zip(encode_mask_texts, encode_non_mask_texts, mask_ids):\n",
        "    add_padding = max_len - len(mask_text)%max_len\n",
        "    size = add_padding + len(mask_text)\n",
        "    padding_id = np.ones(size)\n",
        "    padding_id[len(mask_text):] = 0\n",
        "    mask_text     = np.pad(mask_text,     (0, add_padding), 'constant', constant_values=(0, 0))\n",
        "    mask_id       = np.pad(mask_id,       (0, add_padding), 'constant', constant_values=(0, 0))\n",
        "    non_mask_text = np.pad(non_mask_text, (0, add_padding), 'constant', constant_values=(0, 0))\n",
        "\n",
        "    padding_id = padding_id.reshape(-1, max_len)\n",
        "    mask_id = mask_id.reshape(-1, max_len)\n",
        "    mask_text = mask_text.reshape(-1, max_len)\n",
        "    non_mask_text = non_mask_text.reshape(-1, max_len)\n",
        "\n",
        "    padding_ids.append(padding_id)\n",
        "    pad_masks.append(mask_id)\n",
        "    pad_mask_texts.append(mask_text)\n",
        "    pad_non_mask_texts.append(non_mask_text)\n",
        "  \n",
        "  padding_id = np.concatenate(padding_ids, axis = 0)\n",
        "  pad_mask = np.concatenate(pad_masks, axis = 0)\n",
        "  pad_mask_text = np.concatenate(pad_mask_texts, axis = 0)\n",
        "  pad_non_mask_text = np.concatenate(pad_non_mask_texts, axis = 0)\n",
        "\n",
        "  return pad_non_mask_text, pad_mask_text, padding_id, pad_mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "kR2eib8JDiWs"
      },
      "outputs": [],
      "source": [
        "def Padding_inference(text):\n",
        "  text_len = len(text)\n",
        "  add_padding = max_len - len(text)%max_len\n",
        "  size = add_padding + len(text)\n",
        "  text = np.pad(text, (0, add_padding), 'constant', constant_values=(0, 0))\n",
        "  pad_id = np.zeros(shape = (1, max_len), dtype = np.float32)\n",
        "  pad_id[:, :text_len] = 1\n",
        "  return text.reshape(1, max_len), pad_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "rXzNcndx4EIN"
      },
      "outputs": [],
      "source": [
        "def decode_sentence(tensor):\n",
        "  output = []\n",
        "  for value in tensor:\n",
        "    if value < len(short_corpus):\n",
        "      output.append(short_corpus[value])\n",
        "    else:\n",
        "      output.append(eliminate_corpus[value])\n",
        "  return ' '.join(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "M-6lztjm8zAu"
      },
      "outputs": [],
      "source": [
        "def preprocess(texts, batch_size = batch_size, dtype = tf.float32):\n",
        "  non_mask_data, mask_data, mask_id = MaskingData(texts)\n",
        "  input = encode_sentences(mask_data)\n",
        "  label = encode_sentences(non_mask_data)\n",
        "  non_mask_text, mask_text, padding_id, pad_mask = PaddingData(label, input, mask_id)\n",
        "\n",
        "  non_mask_text = tf.convert_to_tensor(non_mask_text, dtype = dtype)\n",
        "  mask_text = tf.convert_to_tensor(mask_text, dtype = dtype)\n",
        "  padding_id = tf.convert_to_tensor(padding_id, dtype = dtype)\n",
        "  pad_mask = tf.convert_to_tensor(pad_mask, dtype = dtype)\n",
        "\n",
        "  non_mask_text = tf.data.Dataset.from_tensor_slices(non_mask_text)\n",
        "  mask_text = tf.data.Dataset.from_tensor_slices(mask_text)\n",
        "  padding_id = tf.data.Dataset.from_tensor_slices(padding_id)\n",
        "  pad_mask = tf.data.Dataset.from_tensor_slices(pad_mask)\n",
        "\n",
        "  dataset = tf.data.Dataset.zip((non_mask_text, mask_text, padding_id, pad_mask)).shuffle(1000).batch(batch_size, drop_remainder=True)\n",
        "  \n",
        "  return dataset\n",
        "\n",
        "def Preprocess(texts, batch_size = batch_size, dtype = tf.float32):\n",
        "  non_mask_data, mask_data, mask_id = MaskingData(texts)\n",
        "  input = encode_sentences(mask_data)\n",
        "  label = encode_sentences(non_mask_data)\n",
        "  non_mask_text, mask_text, padding_id, pad_mask = PaddingData(label, input, mask_id)\n",
        "\n",
        "  non_mask_text = tf.convert_to_tensor(non_mask_text, dtype = dtype)\n",
        "  mask_text = tf.convert_to_tensor(mask_text, dtype = dtype)\n",
        "  pad_mask = tf.convert_to_tensor(pad_mask, dtype = dtype)\n",
        "\n",
        "  return mask_text, non_mask_text, pad_mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "aaMSr1uwHWGd"
      },
      "outputs": [],
      "source": [
        "Train_dataset = Preprocess(train_data)\n",
        "Valid_dataset = Preprocess(valid_data)\n",
        "Test_dataset = Preprocess(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "7iOBgSouMxN2"
      },
      "outputs": [],
      "source": [
        "train_dataset = preprocess(train_data)\n",
        "valid_dataset = preprocess(valid_data)\n",
        "test_dataset = preprocess(test_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YnblgakZNrIS"
      },
      "source": [
        "# BUILD MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "fR2sEVEZkEbq"
      },
      "outputs": [],
      "source": [
        "class PositionalEncoding(keras.layers.Layer):\n",
        "    def __init__(self, max_steps, max_dims, dtype=tf.float32, **kwargs):\n",
        "        super().__init__(dtype=dtype, **kwargs)\n",
        "        if max_dims % 2 == 1: max_dims += 1 # max_dims must be even\n",
        "        p, i = np.meshgrid(np.arange(max_steps), np.arange(max_dims // 2))\n",
        "        pos_emb = np.empty((1, max_steps, max_dims))\n",
        "        pos_emb[0, :, ::2] = np.sin(p / 10000**(2 * i / max_dims)).T\n",
        "        pos_emb[0, :, 1::2] = np.cos(p / 10000**(2 * i / max_dims)).T\n",
        "        self.positional_embedding = tf.constant(pos_emb.astype(self.dtype))\n",
        "    def call(self, inputs):\n",
        "        shape = tf.shape(inputs)\n",
        "        return inputs + self.positional_embedding[:, :shape[-2], :shape[-1]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "BE0dUIaaNe-i"
      },
      "outputs": [],
      "source": [
        "class MultiheadAttention(keras.layers.Layer):\n",
        "  def __init__(self, n_heads = 8, dropout_rate = 0.1, **kwargs):\n",
        "    super(MultiheadAttention, self).__init__()\n",
        "    self.n_heads = n_heads\n",
        "    self.dropout_rate = dropout_rate\n",
        "  def build(self, batch_input_shape):\n",
        "    self.batch, self.q_time_steps, self.dim = batch_input_shape\n",
        "    self.q_linear = keras.layers.Conv1D(self.dim * self.n_heads, kernel_size = 1, strides = 1, padding = 'valid', use_bias = False)\n",
        "    self.k_linear = keras.layers.Conv1D(self.dim * self.n_heads, kernel_size = 1, strides = 1, padding = 'valid', use_bias = False)\n",
        "    self.v_linear = keras.layers.Conv1D(self.dim * self.n_heads, kernel_size = 1, strides = 1, padding = 'valid', use_bias = False)\n",
        "    self.linear_out = keras.layers.Conv1D(self.dim, kernel_size = 1, strides = 1, padding = 'valid', use_bias = False)\n",
        "    self.drop_out = keras.layers.Dropout(self.dropout_rate)\n",
        "    super().build(batch_input_shape)\n",
        "  def mask_attention(self, q, k, v, mask_q = None, mask_k = None):\n",
        "    if mask_q is None:\n",
        "      mask_q = tf.ones(shape = (q.shape[0], q.shape[1], q.shape[2]))\n",
        "    else:\n",
        "      dim = q.shape[2]\n",
        "      time_series = q.shape[1]\n",
        "      mask_q = tf.stack([mask_q]*self.n_heads*dim, axis = 0)\n",
        "      mask_q = tf.reshape(mask_q, shape = (dim, self.n_heads, -1, time_series)) # (dim, n_heads, batch, time_series)\n",
        "      mask_q = tf.transpose(mask_q, perm = [2, 1, 3, 0]) # (batch, n_heads, time_series, dimension)\n",
        "      mask_q = tf.reshape(mask_q, shape = (-1, time_series, dim)) # (batch * n_head, time_series, dimension)\n",
        "    if mask_k is None:\n",
        "      mask_k = tf.ones(shape = (k.shape[0], k.shape[1], k.shape[2]))\n",
        "    else:\n",
        "      dim = k.shape[2]\n",
        "      time_series = k.shape[1]\n",
        "      mask_k = tf.stack([mask_k]*self.n_heads*dim, axis = 0)\n",
        "      mask_k = tf.reshape(mask_k, shape = (dim, self.n_heads, -1, time_series)) # (dim, n_heads, batch, time_series)\n",
        "      mask_k = tf.transpose(mask_k, perm = [2, 1, 3, 0]) # (batch, n_heads, time_series, dimension)\n",
        "      mask_k = tf.reshape(mask_k, shape = (-1, time_series, dim)) # (batch*n_heads, time_series, dimension)\n",
        "    q = tf.multiply(q, mask_q)\n",
        "    k = tf.multiply(k, mask_k)\n",
        "    v = tf.multiply(v, mask_k)\n",
        "    normalize = tf.math.sqrt(tf.cast(self.dim, dtype=tf.float32))\n",
        "    attention = tf.linalg.matmul(q, tf.transpose(k, perm = [0, 2, 1])) / normalize\n",
        "    norm_attention = tf.nn.softmax(attention, axis = -1)\n",
        "    output = tf.linalg.matmul(norm_attention, v)\n",
        "    return output, norm_attention\n",
        "  def linear_attention(self, input, linear):\n",
        "    timestep = input.shape[1]\n",
        "    output = linear(input)\n",
        "    output = tf.reshape(output, shape = [-1, timestep, self.n_heads, self.dim]) # (batch, timestep, n_heads, dimension)\n",
        "    output = tf.transpose(output, perm = [0, 2, 1, 3])\n",
        "    output = tf.reshape(output, shape = [-1 , timestep, self.dim]) # (batch*n_heads, timestep, dimension)\n",
        "    return output\n",
        "  def call(self, Q, V, mask_q = None, mask_k = None):\n",
        "    K = V\n",
        "    Q = self.linear_attention(Q, self.q_linear)\n",
        "    K = self.linear_attention(K, self.k_linear)\n",
        "    V = self.linear_attention(V, self.v_linear)\n",
        "    output, attention_weight = self.mask_attention(Q, K, V, mask_q = mask_q, mask_k = mask_k)\n",
        "    output = tf.reshape(output, shape = [-1, self.n_heads, self.q_time_steps, self.dim]) # (batch, n_heads, q_time_steps, dimension)\n",
        "    output = tf.transpose(output, perm = [0, 2, 1, 3])\n",
        "    output = tf.reshape(output, shape = [-1, self.q_time_steps, self.n_heads*self.dim]) # (batch, n_heads, q_time_steps, dimension)\n",
        "    output = self.linear_out(output)\n",
        "    output = self.drop_out(output)\n",
        "    return output, attention_weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "V5G55S3wjYkq"
      },
      "outputs": [],
      "source": [
        "class FFN(keras.layers.Layer):\n",
        "  def __init__(self, d_dim = d_dim, drop_rate = drop_rate):\n",
        "    super().__init__()\n",
        "    self.d_dim = d_dim\n",
        "    self.drop = keras.layers.Dropout(drop_rate)\n",
        "    self.normalize = keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "  def build(self, batch_input_shape):\n",
        "    self.dense = keras.layers.Dense(self.d_dim, activation = 'relu')\n",
        "    self.d_model = keras.layers.Dense(batch_input_shape[-1])\n",
        "  def call(self, input):\n",
        "    emb = self.dense(input)\n",
        "    bottle_neck = self.d_model(emb)\n",
        "    add = bottle_neck + input\n",
        "    normalize = self.normalize(add)\n",
        "    output = self.drop(normalize)\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "PgSs1GYqgNQy"
      },
      "outputs": [],
      "source": [
        "class transformer_block(keras.layers.Layer):\n",
        "  def __init__(self, n_heads = n_heads, drop_rate = drop_rate, d_dim = d_dim):\n",
        "    super(transformer_block, self).__init__()\n",
        "    self.n_heads = n_heads\n",
        "    self.drop_rate = drop_rate\n",
        "    #self.MulAttention = MultiheadAttention(n_heads, drop_rate)\n",
        "    self.MulAttention = keras.layers.MultiHeadAttention(num_heads = n_heads, key_dim = d_dim)\n",
        "    self.ffn = FFN(d_dim, drop_rate)\n",
        "    self.normalize = keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "  def call(self, inputs, mask_q = None, mask_k = None):\n",
        "    #x, attention_weight = self.MulAttention(inputs, mask_q, mask_k)\n",
        "    x = self.MulAttention(inputs, inputs)\n",
        "    x = x + inputs\n",
        "    normalize = self.normalize(x)\n",
        "    output = self.ffn(normalize)\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "EcqGH39KRjMi"
      },
      "outputs": [],
      "source": [
        "# dump_inp = tf.random.uniform(shape = (batch_size, max_len, max_dim))\n",
        "# dump_2d_inp = tf.random.uniform(shape = (batch_size, max_len))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "qJ_j1BZ172eD"
      },
      "outputs": [],
      "source": [
        "class MaskLanguageModel(keras.Model):\n",
        "  def __init__(self, d_dim = d_dim, vocab_size = corpus_len ,max_steps = max_len, max_dims = max_dim, n_heads = n_heads, drop_rate = drop_rate, n_blocks = n_blocks):\n",
        "    super().__init__()\n",
        "    self.position = PositionalEncoding(max_steps = max_steps, max_dims = max_dims)\n",
        "    self.transformers = [transformer_block(n_heads = n_heads, drop_rate = drop_rate, d_dim = d_dim) for _ in range(n_blocks)]\n",
        "    self.dense = keras.layers.Dense(vocab_size)\n",
        "    self.embed = keras.layers.Embedding(vocab_size, max_dims, input_length = max_steps)\n",
        "  def call(self, inputs, mask_q = None, mask_k = None, training = False):\n",
        "    embed = self.embed(inputs)\n",
        "    pos_emb = self.position(embed)\n",
        "    x = self.transformers[0](pos_emb, mask_q, mask_k)\n",
        "    for block in self.transformers[1:]:\n",
        "      x = block(x)\n",
        "    output = self.dense(x)\n",
        "    output = tf.nn.softmax(output, axis = -1)\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "7WyCsmzMu6TD"
      },
      "outputs": [],
      "source": [
        "# test_model = MaskLanguageModel()\n",
        "# test_model(dump_2d_inp).shape\n",
        "# test_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bI2UG-NapnRG"
      },
      "source": [
        "# CUSTOM TRAINING LOOP (something got trouble with custom training loop)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "cq4fpsbutslW"
      },
      "outputs": [],
      "source": [
        "model = MaskLanguageModel()\n",
        "loss_fn = keras.losses.SparseCategoricalCrossentropy()\n",
        "optimizer = keras.optimizers.experimental.AdamW()\n",
        "metrics_train = keras.metrics.SparseCategoricalAccuracy()\n",
        "metrics_test  = keras.metrics.SparseCategoricalAccuracy()\n",
        "#model.build((batch_size, max_len))\n",
        "@tf.function\n",
        "def train_step(input, label):\n",
        "  with tf.GradientTape() as tape:\n",
        "    #output = model([input], mask_q = padding_id, mask_k = padding_id, training = True)\n",
        "    output = model(input)\n",
        "    loss = loss_fn(label, output, sample_weight = pad_mask)\n",
        "  grads = tape.gradient(loss, model.trainable_weights)\n",
        "  optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
        "  metrics_train.update_state(label, output, sample_weight = pad_mask)\n",
        "  return loss\n",
        "\n",
        "@tf.function\n",
        "def test_step(input, label):\n",
        "  #output = model([input], mask_q = padding_id, mask_k = padding_id, training = False)\n",
        "  output = model(input)\n",
        "  metrics_test.update_state(label, output, sample_weight = pad_mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vyBVyEA-JkmQ",
        "outputId": "378b67c3-2652-4c6d-d74d-000afed15455"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 1/4:  "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 920/920 [03:44<00:00,  4.10it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The training loss is 0.71457839012146\n",
            "The training accuracy is 0.2183450609445572\n",
            "The valid accuracy is 0.22104774415493011\n",
            "epoch 2/4:  "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 920/920 [02:56<00:00,  5.21it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The training loss is 0.6455916166305542\n",
            "The training accuracy is 0.22056061029434204\n",
            "The valid accuracy is 0.22254572808742523\n",
            "epoch 3/4:  "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 920/920 [02:49<00:00,  5.44it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The training loss is 0.658482551574707\n",
            "The training accuracy is 0.21913591027259827\n",
            "The valid accuracy is 0.22322088479995728\n",
            "epoch 4/4:  "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 920/920 [02:47<00:00,  5.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The training loss is 0.6833505630493164\n",
            "The training accuracy is 0.21943439543247223\n",
            "The valid accuracy is 0.22016161680221558\n"
          ]
        }
      ],
      "source": [
        "list_loss = []\n",
        "train_acc = []\n",
        "valid_acc = []\n",
        "for i in range(num_epochs):\n",
        "  print(f'epoch {i+1}/{num_epochs}: ', end = ' ')\n",
        "  for label, input, padding_id, pad_mask in tqdm(train_dataset):\n",
        "    loss = train_step(input, label)\n",
        "    list_loss.append(loss.numpy())\n",
        "  print(f'The training loss is {loss}')\n",
        "  print(f'The training accuracy is {metrics_train.result()}')\n",
        "  train_acc.append(metrics_train.result())\n",
        "  metrics_train.reset_states()\n",
        "\n",
        "  for label, input, padding_id, pad_mask in valid_dataset:\n",
        "    test_step(input, label)\n",
        "  print(f'The valid accuracy is {metrics_test.result()}')\n",
        "  valid_acc.append(metrics_test.result())\n",
        "  metrics_test.reset_states()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "hx2y9eExkWTc",
        "outputId": "a843943c-4870-4e53-d3b8-99955b6adec7"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(train_acc, label = 'train_accuracy')\n",
        "plt.plot(valid_acc, label = 'valid_accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tMSuXZhFDtVJ"
      },
      "source": [
        "# FIT TRAINING LOOP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VjFHDR9eEimR",
        "outputId": "213efb16-4f61-4737-81fc-90109b8c4d0e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "921/921 [==============================] - 171s 178ms/step - loss: 0.5070\n",
            "Epoch 2/3\n",
            "921/921 [==============================] - 152s 165ms/step - loss: 0.3677\n",
            "Epoch 3/3\n",
            "921/921 [==============================] - 155s 168ms/step - loss: 0.3387\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb5642ea250>"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "loss_fn = keras.losses.SparseCategoricalCrossentropy()\n",
        "optimizer = keras.optimizers.experimental.AdamW()\n",
        "mask_text, non_mask_text, pad_id = Train_dataset\n",
        "model = MaskLanguageModel()\n",
        "model.compile(loss = loss_fn, \n",
        "              optimizer = optimizer, \n",
        "              loss_weights = pad_id\n",
        "              )\n",
        "history = model.fit(mask_text, non_mask_text, \n",
        "                    epochs = 5, \n",
        "                    batch_size = batch_size\n",
        "                    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CtrkcW5FJhB-"
      },
      "source": [
        "# Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "8T_T2rCOEbsb"
      },
      "outputs": [],
      "source": [
        "def inference(text):\n",
        "  text = text.lower()\n",
        "  mask_id = text.split().index('[mask]')\n",
        "  encode = encode_sentence(text)\n",
        "  padding, pad_id = Padding_inference(encode)\n",
        "  output = model(padding.reshape(1, max_len)).numpy()\n",
        "  result = np.argmax(output, axis = -1)\n",
        "  decode = decode_sentence(result[0][:len(text.split())])\n",
        "  return decode.split()[mask_id]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "tJw43Ej7K6SO",
        "outputId": "52abe4f2-9eea-4739-d48e-30921bb1a1ab"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'furnivals'"
            ]
          },
          "execution_count": 99,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "inference('How are [mask] today')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vSFIkC4SMvSj"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyM0WBDdYCwy8HnUlpiFtACP",
      "collapsed_sections": [
        "-k4HkeZpNwbS",
        "bI2UG-NapnRG"
      ],
      "include_colab_link": true,
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
